# import os
# import nltk
# from nltk.tokenize import sent_tokenize

# # Ensure current dir nltk_data is added
# #nltk.data.path.append(os.path.join(os.getcwd(), 'nltk_data'))

# # Example corpus
# corpus = "Your text here. Another sentence! One more?"

# # Sentence tokenization
# sentences = sent_tokenize(corpus)
# print(sentences)

import nltk
nltk.download('wordnet')